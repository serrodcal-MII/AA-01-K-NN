{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aprendizaje basado en instancias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En esta sesión de trabajo con Jupyter aplicaremos los conceptos presentados en el módulo sobre aprendizaje basado en instancias al conjunto de datos Iris."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Procesado de los datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El conjunto de [datos Iris](https://es.wikipedia.org/wiki/Iris_flor_conjunto_de_datos) contiene datos sobre cuatro características morfológicas de tres especies de la flor Iris: Iris setosa, Iris virginica e Iris versicolor. En concreto hay 50 muestras de cada especie. Para cada una de ellas se tiene información sobre el largo y el ancho del pétalo y el sépalo, medidos en centímetros."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lo primero que vamos a hacer es cargar el conjunto de datos Iris incluido en *Scikit-learn*, usando la función [`load_iris()`](http://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_iris.html) incluido en la librería `sklearn.datasets`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "\n",
    "iris = load_iris()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este conjunto de datos es un diccionario con varios campos:\n",
    "* `data`: Es el conjunto de datos, se trata de un array en el que cada componente es un array con las características de cada instancia.\n",
    "* `target`: Es el conjunto de valores de clasificación para cada instancia. Es un array del mismo tamaño que `data`, en el que se indica el valor de clasificación de cada instancia, en el mismo orden en que éstas se encuentran en el array `data`.\n",
    "* `target_names`: Es un array con los nombres de cada valor de clasificación.\n",
    "* `feature_names`: Es un array con los nombres de cada característica.\n",
    "* `DESCR`: Es una descripción del conjunto de datos.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El valor `i`-ésimo del array de datos y su valor de clasificación se pueden obtener con la siguiente función:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def datoIesimo(i):\n",
    "    print(\"Dato (\",i,\"): \",iris['data'][i])\n",
    "    print(\"  Clasificación: \",iris['target'][i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los valores de clasificación almacenados en el array `target` son valores numéricos contados desde 0 en adelante y se corresponden con la clasificación almacenada en el array `target_names`. Es decir el valor de clasificación `j` se corresponde con la clasificación `target_names[j]`. Teniendo esto en cuenta podemos mejorar la función anterior para proporcionar esta información:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def datoIesimo(i):\n",
    "    print(\"Dato (\",i,\"): \",iris['data'][i])\n",
    "    print(\"  Clasificación: \",iris['target_names'][iris['target'][i]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De la misma forma, los valores que contiene cada dato se corresponden con los valores de las características, en el mismo orden en que aparecen en el array `feature_names`. Finalmente, la función anterior se puede mejorar asociando cada valor del dato con la característica correspondiente:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def datoIesimo(i):\n",
    "    print(\"Características del dato número \",i,\":\")\n",
    "    for j in range(4):\n",
    "        print(\" \",iris['feature_names'][j],\": \",iris['data'][i][j])\n",
    "    print(\"  Clasificación: \",iris['target_names'][iris['target'][i]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El último valor devuelto por la función `load_iris()` es una descripción del conjunto de datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(iris['DESCR'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Almacenamos cada uno de los campos que resultan de interés para este ejercicio en variables distintas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_data, y_data, X_names, y_names = \\\n",
    "    iris.data, iris.target, iris.feature_names, iris.target_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos visualizar el conjunto de datos usando la librería `matplotlib`. Para esto, consideramos un par de características \n",
    "(por ejemplo las dos primeras) y presentamos en un gráfico 2D un conjunto de puntos que representan cada uno de los ejemplos del conjunto de datos. Para diferenciar los valores de clasificación usamos distintas formas y colores para cada uno de ellos: cuadrados rojos para el primer valor de clasificación (Iris setosa), círculos verdes para el segundo valor de clasificación (Iris versicolor) y rombos azules para el tercer valor de clasificación (Iris virgínica)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cargamos la librería [`pyplot`](https://matplotlib.org/api/pyplot_api.html) de la biblioteca `matplotlib` con el nombre `plt`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El proceso para dibujar los datos consiste en limpiar el lienzo (`plt.clf()`) y para cada terna formada por el valor de clasificación (`range(len(y_names))`), la forma (`\"soD\"`) y el color (`\"rgb\"`) deseados, recoger en las variables `xs` e `ys` los valores de las características a representar de todos los datos con el valor de clasificación considerado. Estos puntos se representan con el método (`plt.scatter`) con la forma y el color considerados. Finalmente etiquetamos los ejes horizontal y vertical con los nombres de las características representadas.\n",
    "\n",
    "El siguiente trozo de código sirve para visualizar como se distribuyen los datos con respecto a los valores de las características longitud de sépalo y anchura de sépalo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.clf()\n",
    "for tipo,marca,color in zip(range(len(y_names)),\"soD\",\"rgb\"):\n",
    "    xs=X_data[y_data==tipo,0]\n",
    "    ys=X_data[y_data==tipo,1]\n",
    "    plt.scatter(xs,ys,marker=marca,c=color)\n",
    "plt.xlabel(\"Longitud de sépalo\")\n",
    "plt.ylabel(\"Anchura de sépalo\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este gráfico se puede observar que los datos de las flores de la variedad setosa se pueden separar fácilmente de los otros, que se mezclan un poco. \n",
    "\n",
    "Este proceso se puede definir como el efecto de una función:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def representacion_grafica(datos,caracteristicas,objetivo,clases,c1,c2):\n",
    "    for tipo,marca,color in zip(range(len(clases)),\"soD\",\"rgb\"):\n",
    "        xs = datos[objetivo == tipo,c1]\n",
    "        ys = datos[objetivo == tipo,c2]\n",
    "        plt.scatter(xs,ys,marker=marca,c=color)\n",
    "    plt.xlabel(caracteristicas[c1])\n",
    "    plt.ylabel(caracteristicas[c2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos utilizar esta función para representar gráficamente la distribución de los datos con respecto a cada pareja de características. Eso se consigue dividiendo el lienzo en seis trozos, en 2 filas y 3 columnas con las correspondientes llamadas al método `plt.subplot`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def representacion_conjunta():\n",
    "    plt.clf()\n",
    "    plt.rcParams[\"figure.figsize\"] = [18,12]\n",
    "    plt.subplot(231)\n",
    "    representacion_grafica(X_data,X_names,y_data,y_names,0,1)\n",
    "    plt.subplot(232)\n",
    "    representacion_grafica(X_data,X_names,y_data,y_names,0,2)\n",
    "    plt.subplot(233)\n",
    "    representacion_grafica(X_data,X_names,y_data,y_names,0,3)\n",
    "    plt.subplot(234)\n",
    "    representacion_grafica(X_data,X_names,y_data,y_names,1,2)\n",
    "    plt.subplot(235)\n",
    "    representacion_grafica(X_data,X_names,y_data,y_names,1,3)\n",
    "    plt.subplot(236)\n",
    "    representacion_grafica(X_data,X_names,y_data,y_names,2,3)\n",
    "    plt.subplots_adjust(wspace=0.2,hspace=0.2)\n",
    "    plt.show()\n",
    "\n",
    "representacion_conjunta()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De los gráficos anteriores se puede deducir que las características que mejor separan los datos (y por tanto las que mejor sirven para clasificarlos) son la longitud y anchura del pétalo. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aprendizaje basado en instancias: Algoritmo k-NN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a aplicar el algoritmo k-NN al conjunto de datos Iris para clasificar nuevas instancias. Para que esto tenga sentido, tendremos que dividir el conjunto de datos original en dos trozos: un conjunto de entrenamiento para el aprendizaje y un conjunto de prueba para la evaluación. Esto lo conseguimos con la función `train_test_split` de la librería `sklearn.model_selection`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para usar esta función debemos proporcionar el array de datos original `X_data`, el array de valores de clasificación `y_data`, el tamaño de uno de los conjuntos resultado, `test_size` o `train_size`, que puede ser un valor entero indicado un valor absoluto del número de ejemplos o un número real entre 0 y 1, que representa un porcentaje del conjnto de datos original. Esta función realiza una selección aleatoria de índices en el rango de los arrays `X_data` e `y_data`, respetando la proporción indicada. Una vez hecho esto, devuelve los arrays de datos resultado de seleccionar en `X_data` e `y_data` los valores asociados a dichos índices, y los restantes. El parámetro `stratify` sirve para indicar con respecto a qué valores se quieren estratificar los datos (normalmente el valor de clasificación)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = \\\n",
    "  train_test_split(X_data,y_data,test_size = 0.33,\n",
    "                   random_state=4861,stratify=y_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos ver gráficamente cómo se han distribuido los datos en los conjuntos de entrenamiento y prueba, representando simultáneamente estos conjuntos de datos junto con el conjunto de datos original."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams[\"figure.figsize\"] = [18,6]\n",
    "plt.clf()\n",
    "splt = plt.subplot(131)\n",
    "splt.set_xlim(4,8)\n",
    "splt.set_ylim(1.8,4.5)\n",
    "splt.set_title(\"Conjunto de datos\")\n",
    "representacion_grafica(X_data,X_names,y_data,y_names,0,1)\n",
    "splt = plt.subplot(132)\n",
    "splt.set_xlim(4,8)\n",
    "splt.set_ylim(1.8,4.5)\n",
    "splt.set_title(\"Conjunto de entrenamiento\")\n",
    "representacion_grafica(X_train,X_names,y_train,y_names,0,1)\n",
    "splt = plt.subplot(133)\n",
    "splt.set_xlim(4,8)\n",
    "splt.set_ylim(1.8,4.5)\n",
    "splt.set_title(\"Conjunto de prueba\")\n",
    "representacion_grafica(X_test,X_names,y_test,y_names,0,1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El algoritmo de clasificación **k**-*NN* se encuentra en la librería `sklearn.neighbors` implementado mediante la clase `KNeighborsClassifier`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creamos una instancia de este algoritmo con un valor de **k** igual a 5, este valor se indica con el parámetro `n_neighbors`. Para indicar la distancia a utilizar usamos el paramétro `p`, que será el valor del que dependerá la distancia Minkowski:\n",
    "$$d_p(\\textbf{x},\\textbf{y})=(\\sum_{i=1}^n(x_i-y_i)^p)^{1/p}$$\n",
    "\n",
    "Como recordaréris, un valor de `p` igual a `1` se corresponde con el uso de la distancia Manhattan y un valor de `p` igual a `2` se corresponde con el uso de la distancia euclídea. También se puede usar otra distancia, prorcionándola como valor del parámetro `metric`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn1 = KNeighborsClassifier(n_neighbors=5,p=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Todos las implementaciones de algoritmos de aprendizaje en *Scikit-learn* admiten una serie de métodos con la misma funcionalidad:\n",
    "* `fit`: Sirve para entrenar el modelo asociado, es decir aprender los parámetros que sirven para ajustarlo al conjunto de datos. Recibe como argumentos el array de características de los ejemplos y el de sus valores de clasificación.\n",
    "* `predict`: Sirve para evaluar el modelo entrenado sobre un array de ejemplos. Recibe como argumento el array de características de los ejemplos y devuelve el array con sus valores de clasificación según el modelo.\n",
    "* `score`: Mide el rendimiento del modelo entrenado sobre un array de ejemplos. Recibe como argumentos el array de características de los ejemplos y el de sus valores de clasificación. Devuelve el rendimiento del modelo sobre dicho conjunto de ejemplos.\n",
    "\n",
    "Una vez creada la instancia del algoritmo de aprendizaje, hay que entrenarla con el conjunto de ejemplos de entrenamiento. En este caso, el entrenamiento sirve para organizar los datos de la mejor forma posible para calcular las distancias en las que se basa el proceso de clasificación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn1.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Al entrenar el modelo, podemos ver los valores de los parámetros de los que depende el proceso de entrenamiento. Algunos de ellos (`algorithm`, `leaf_size` y `n_jobs`) son relativos al proceso de cálculo de las distancias necesarias para determinar los mejores vecinos, es decir, parámetros del algoritmo de entrenamiento; y otros (`metric`, `metric_params`, `n_neighbors`, `p` y `weights`) son relativos al proceso de selección de los mejores vecinos y de clasificación, es decir, parámetros del modelo de clasificación.\n",
    "\n",
    "Veamos ahora el valor de clasificación de los ejemplos del conjunto de prueba."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn1.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si comparamos este array con el de valores de clasificación del conjunto de prueba, `y_test`, podemos calcular el rendimiento del modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_clas = knn1.predict(X_test)\n",
    "y_clas[y_clas != y_test]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esto es precisamente lo que calcula el tercero de los métodos que hemos mencionado antes, `score`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn1.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Antes se ha visto otro parámetro, `weights`, del modelo de clasificación. Se trata de un forma de ponderar los valores de clasificación de los mejores vecinos. El valor por defecto es `uniform`, que indica que los valores de clasificación de los mejores vecinos se tratan de forma uniforme, sin dar más importancia a unos que a otros. El valor `distance` indica que se debe dar más importancia a los valores de clasificación de los mejores vecinos más cercanos. Esto puede afectar al resultado de la clasificación, haciendo variar el rendimiento.\n",
    "\n",
    "Para usar este parámetro, tenemos que indicar su valor en el momento de crear la instancia del algoritmo de clasificación:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn2 = KNeighborsClassifier(n_neighbors=5,p=2,weights='distance')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entrenamos la nueva instancia con el mismo conjunto de ejemplos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn2.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Y vamos a ver si hay algún cambio en el rendimiento del modelo obtenido"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn2.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Veamos ahora el efecto que produce cambiar la distancia. Vamos a construir una instancia del algoritmo de clasificación usando la distancia Manhattan. Para esto, solo hay que indicar el valor `1` para el parámetro `p`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn3 = KNeighborsClassifier(n_neighbors=5,p=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entrenamos la instancia creada con el conjunto de entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn3.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Y analizamos el rendimiento del modelo obtenido"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn3.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este caso el resultado es peor que con la distancia euclídea. En este caso, dado que las características miden propiedades similares (longitudes) era de esperar que la distancia euclídea funcionase mejor que la Manhattan. Esta última resulta más útil cuando las características miden propiedades que no tienen nada en común."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalización"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El último factor que vamos a ver de los influyen en el modelo **k**-*NN* es la normalización. En este caso, las medidas de longitud de pétalos y sépalos tienen mayor rango que las medidas de anchura. Eso podría influir en las distancias entre los ejemplos. Para evitarlo, podemos normalizar los datos. *Scikit-learn* proporciona varias formas de normalizar un conjunto de datos. Aquí usamos la implementada en la clase `StandardScaler` de la librería `sklearn.preprocessing`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Al igual que los modelos de clasificación, el normalizador se 'entrena' con el conjunto de datos de entrenamiento, para determinar su media y su varianza. Esto se consigue con el método `fit`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalizador = StandardScaler().fit(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A partir de los valores aprendidos, se pueden modificar los datos originales de forma que el resultado quede con un valor de la media aproximadamente igual a 0 y un valor de la varianza aproximadamente igual a 1. Esto se consigue con el médodo `transform`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xn_train = normalizador.transform(X_train)\n",
    "Xn_test = normalizador.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Es muy importante que los ejemplos del conjunto de prueba se normalicen de la misma forma que los del conjunto de entrenamiento, para que el modelo aprendido funcione correctamente.\n",
    "\n",
    "Los valores aprendidos por el normalizador se almacenan en los parámetros `mean_` para las medias de las características, `var_` para las varianzas y `scale_` para los factores multiplicativos que cambian la escala."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalizador.mean_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalizador.var_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalizador.scale_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import mean,var\n",
    "print(\"Media de los datos originales: \",mean(X_train[:,0]))\n",
    "print(\"Media de los datos normalizados: \",mean(Xn_train[:,0]))\n",
    "print(\"Varianza de los datos originales: \",var(X_train[:,0]))\n",
    "print(\"Varianza de los datos normalizados: \",var(Xn_train[:,0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos representar gráficamente los datos antes y después de la normalización para ver las diferencias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams[\"figure.figsize\"] = [18,6]\n",
    "plt.clf()\n",
    "splt = plt.subplot(121)\n",
    "splt.set_xlim(4,8)\n",
    "splt.set_ylim(1.8,4.5)\n",
    "splt.set_title(\"Conjunto de datos sin normalizar\")\n",
    "representacion_grafica(X_data,X_names,y_data,y_names,0,1)\n",
    "splt = plt.subplot(122)\n",
    "splt.set_xlim(-3.5,3.5)\n",
    "splt.set_ylim(-3.5,3.5)\n",
    "splt.set_title(\"Conjunto de datos normalizados\")\n",
    "Xn_data = normalizador.transform(X_data)\n",
    "representacion_grafica(Xn_data,X_names,y_data,y_names,0,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con estos nuevos datos, entrenamos una nueva instancia del algoritmo **k**-*NN*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn4 = KNeighborsClassifier(n_neighbors=5,p=2,weights='distance')\n",
    "knn4.fit(Xn_train,y_train)\n",
    "knn4.score(Xn_test,y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
